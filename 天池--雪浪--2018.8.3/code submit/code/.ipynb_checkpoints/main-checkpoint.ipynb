{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行main函数即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    import os\n",
    "    import shutil\n",
    "    import cv2\n",
    "    import random\n",
    "    from random import choice\n",
    "    from imgaug import augmenters as iaa\n",
    "    import imgaug as ia\n",
    "    import keras\n",
    "    from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten,BatchNormalization,Activation,AveragePooling2D,Concatenate\n",
    "    from keras.models import Model\n",
    "    from keras.preprocessing import image\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from keras.models import load_model  \n",
    "    from keras.layers import GlobalAveragePooling2D,Flatten\n",
    "    from keras.optimizers import Adam,SGD\n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "    from keras.callbacks import ModelCheckpoint\n",
    "    import matplotlib.pyplot as plt\n",
    "    from keras.applications import inception_resnet_v2\n",
    "    from keras.models import load_model\n",
    "    import keras.backend as backend\n",
    "    import time\n",
    "    import csv\n",
    "    import sys\n",
    "    \n",
    "    #创建normal和bad文件夹 normal 1316张 bad 706张\n",
    "    if not os.path.isdir(\"../data/normal\"):\n",
    "        os.mkdir(\"../data/normal\")\n",
    "    if not os.path.isdir(\"../data/bad\"):\n",
    "        os.mkdir(\"../data/bad\")\n",
    "    for i in os.listdir(\"../data/\"):\n",
    "        if i[-3:] != 'zip' and \"test\" not in i and i!='bad' and i!= 'normal':\n",
    "            for j in os.listdir(\"../data/\" + i):\n",
    "                if(j == \"正常\"):\n",
    "                    for m in os.listdir(\"../data/\" + i + \"/\" + j):\n",
    "                        if m[-3:] == 'jpg':\n",
    "                            shutil.copy(\"../data/\" + i + \"/\" + j + \"/\" + m,\"../data/normal/\")\n",
    "                else:\n",
    "                    for m in os.listdir(\"../data/\" + i + \"/\" + j):\n",
    "                        if m[-3:] == 'jpg':\n",
    "                            shutil.copy(\"../data/\" + i + \"/\" + j + \"/\" + m,\"../data/bad/\")\n",
    "                            \n",
    "    #划分出验证集\n",
    "    val_list_bad = random.sample(os.listdir(\"../data/bad\"),81)\n",
    "    val_list_normal = random.sample(os.listdir(\"../data/normal\"),132)\n",
    "\n",
    "    if not os.path.isdir(\"../data/val\"):\n",
    "        os.mkdir(\"../data/val\")\n",
    "    if not os.path.isdir(\"../data/val/normal\"):\n",
    "        os.mkdir(\"../data/val/normal\")\n",
    "    if not os.path.isdir(\"../data/val/bad\"):\n",
    "        os.mkdir(\"../data/val/bad\")\n",
    "    for i in val_list_bad:\n",
    "        shutil.copy(\"../data/bad/\"+i,\"../data/val/bad/\")\n",
    "    for i in val_list_normal:\n",
    "        shutil.copy(\"../data/normal/\"+i,\"../data/val/normal/\") \n",
    "        \n",
    "    #对训练集里面的每张图进行resize \n",
    "    if not os.path.isdir(\"../data/normal_68\"):\n",
    "        os.mkdir(\"../data/normal_68\")\n",
    "    if not os.path.isdir(\"../data/bad_68\"):\n",
    "        os.mkdir(\"../data/bad_68\")\n",
    "\n",
    "    for i in os.listdir(\"../data/normal/\"): \n",
    "        path = \"../data/normal/\" + i\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img, (800, 600), interpolation=cv2.INTER_AREA)\n",
    "        cv2.imwrite('../data/normal_68/' + i, img)\n",
    "\n",
    "    for i in os.listdir(\"../data/bad/\"): \n",
    "        path = \"../data/bad/\" + i\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img, (800, 600), interpolation=cv2.INTER_AREA)\n",
    "        cv2.imwrite('../data/bad_68/' + i, img)\n",
    "        \n",
    "    if not os.path.isdir(\"../data/train\"):\n",
    "        os.mkdir(\"../data/train\")\n",
    "    if not os.path.isdir(\"../data/train/bad\"):\n",
    "        os.mkdir(\"../data/train/bad\")\n",
    "    if not os.path.isdir(\"../data/train/normal\"):\n",
    "        os.mkdir(\"../data/train/normal\")\n",
    "\n",
    "    for i in os.listdir(\"../data/bad_68/\"):\n",
    "        shutil.copy(\"../data/bad_68/\"+i,\"../data/train/bad/\")\n",
    "    for i in os.listdir(\"../data/normal_68/\"):\n",
    "        shutil.copy(\"../data/normal_68/\"+i,\"../data/train/normal/\")\n",
    "\n",
    "\n",
    "    #进行aug\n",
    "    #增强到5000\n",
    "    TRAIN_DIR = \"../data/bad_68/\"\n",
    "    TRAIN_AUG_DIR = \"../data/train/bad/\"\n",
    "\n",
    "\n",
    "    seq = iaa.Sequential([\n",
    "                iaa.Fliplr(0.5),\n",
    "                iaa.Flipud(0.5),\n",
    "                iaa.Multiply((0.9, 1.1)),\n",
    "            ])\n",
    "\n",
    "    normal_list = os.listdir(TRAIN_AUG_DIR)\n",
    "\n",
    "    k = len(normal_list)\n",
    "    imageList = []\n",
    "    m = k\n",
    "    while m < 5000:\n",
    "        image = cv2.imread(TRAIN_AUG_DIR + choice(normal_list))\n",
    "        imageList.append(image)\n",
    "        m += 1\n",
    "\n",
    "        if m == 3000:\n",
    "            images_aug = seq.augment_images(imageList)\n",
    "            for n in range(len(images_aug)):\n",
    "                cv2.imwrite(TRAIN_AUG_DIR + \"aug_\" + str(k+n) + \".jpg\",images_aug[n])\n",
    "            imageList.clear()\n",
    "        #写入到文件中\n",
    "        if m == 5000:\n",
    "            images_aug = seq.augment_images(imageList)\n",
    "            for n in range(len(images_aug)):\n",
    "                cv2.imwrite(TRAIN_AUG_DIR + \"aug_\" + str(3000+n) + \".jpg\",images_aug[n])\n",
    "            imageList.clear()\n",
    "\n",
    "    #增强到5000\n",
    "    TRAIN_DIR = \"../data/normal_68/\"\n",
    "    TRAIN_AUG_DIR = \"../data/train/normal/\"\n",
    "    import cv2\n",
    "    import os\n",
    "    from random import choice\n",
    "    from imgaug import augmenters as iaa\n",
    "    import imgaug as ia\n",
    "\n",
    "    seq = iaa.Sequential([\n",
    "                iaa.Fliplr(0.5),\n",
    "                iaa.Flipud(0.5),\n",
    "                iaa.Multiply((0.9, 1.1)),\n",
    "            ])\n",
    "\n",
    "    normal_list = os.listdir(TRAIN_AUG_DIR)\n",
    "\n",
    "    k = len(normal_list)\n",
    "    imageList = []\n",
    "    m = k\n",
    "    while m < 5000:\n",
    "        image = cv2.imread(TRAIN_AUG_DIR + choice(normal_list))\n",
    "        imageList.append(image)\n",
    "        m += 1\n",
    "\n",
    "        if m == 3000:\n",
    "            images_aug = seq.augment_images(imageList)\n",
    "            for n in range(len(images_aug)):\n",
    "                cv2.imwrite(TRAIN_AUG_DIR + \"aug_\" + str(k+n) + \".jpg\",images_aug[n])\n",
    "            imageList.clear()\n",
    "        #写入到文件中\n",
    "        if m == 5000:\n",
    "            images_aug = seq.augment_images(imageList)\n",
    "            for n in range(len(images_aug)):\n",
    "                cv2.imwrite(TRAIN_AUG_DIR + \"aug_\" + str(3000+n) + \".jpg\",images_aug[n])\n",
    "            imageList.clear()\n",
    "            \n",
    "    #建立模型\n",
    "    model = inception_resnet_v2.InceptionResNetV2(weights='imagenet', include_top=False,input_shape=(600,800,3))\n",
    "    x = model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    predictions = Dense(2,activation='softmax',name='predictions')(x)\n",
    "    densenet_model = Model(inputs = model.input, outputs = predictions)\n",
    "    #优化器为adam\n",
    "    adam = Adam(lr=0.001)\n",
    "\n",
    "    print(\"正常\",len(os.listdir(\"../data/train/normal\")))\n",
    "    print(\"异常\",len(os.listdir(\"../data/train/bad\")))\n",
    "\n",
    "    image_generator = ImageDataGenerator(\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            rescale=1./255)\n",
    "    train_generator = image_generator.flow_from_directory(directory='../data/train/',\n",
    "                                                         target_size=(600,800),\n",
    "                                                         batch_size=8,\n",
    "                                                         class_mode='categorical')\n",
    "\n",
    "\n",
    "    class CustomModelCheckpoint(keras.callbacks.Callback): \n",
    "        def __init__(self, model, path):\n",
    "            self.model = model\n",
    "            self.path = path\n",
    "            self.best_loss = np.inf\n",
    "            self.best_auc = 0\n",
    "\n",
    "        def on_epoch_end(self, epoch, logs=None): \n",
    "            start = time.time()\n",
    "            y_val_predict_all = []\n",
    "            y_val = []\n",
    "            #读取验证集normal的一张图像\n",
    "            for i in os.listdir(\"../data/val/normal\"):\n",
    "                img = cv2.imread(\"../data/val/normal/\" + i)\n",
    "                #转换为rgb\n",
    "                img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, (800, 600), interpolation=cv2.INTER_AREA)\n",
    "                batch_x = np.zeros((1,600,800,3),backend.floatx())\n",
    "                batch_x[0] = img\n",
    "                y_val_predict = self.model.predict(batch_x/255.,verbose=0,batch_size=8)\n",
    "                #取其中可能性最大的为该图片的有问题与否可能性\n",
    "                y_val_predict = np.max(y_val_predict,axis=0)[0]\n",
    "                y_val_predict_all.append(y_val_predict)\n",
    "                #normal 可能性应该为0\n",
    "                y_val.append(0)\n",
    "            print(\"正常的预测完成\")\n",
    "\n",
    "            #读取验证集bad的一张图像\n",
    "            for i in os.listdir(\"../data/val/bad\"):\n",
    "                img = cv2.imread(\"../data/val/bad/\" + i)\n",
    "                #转换为rgb\n",
    "                img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, (800, 600), interpolation=cv2.INTER_AREA)\n",
    "                batch_x = np.zeros((1,600,800,3),backend.floatx())\n",
    "                batch_x[0] = img\n",
    "\n",
    "                y_val_predict = self.model.predict(batch_x/255.,verbose=0,batch_size=8)\n",
    "\n",
    "                #取其中可能性最大的为该图片的有问题与否可能性\n",
    "                y_val_predict = np.max(y_val_predict,axis=0)[0]\n",
    "                y_val_predict_all.append(y_val_predict)\n",
    "                #bad 可能性应该为1\n",
    "                y_val.append(1)\n",
    "            print(\"瑕疵的预测完成\")\n",
    "\n",
    "            print(\"验证集验证完成\")\n",
    "\n",
    "            end = time.time()\n",
    "\n",
    "            print(\"用时:\",end - start)\n",
    "\n",
    "\n",
    "            from sklearn import metrics\n",
    "            val_auc = metrics.roc_auc_score(y_val,y_val_predict_all)\n",
    "            print('val_auc:',val_auc)\n",
    "\n",
    "            abc = np.array(y_val_predict_all)\n",
    "            abc[abc>=0.5] = 1\n",
    "            abc[abc<0.5] = 0\n",
    "            acc = np.sum(abc == np.array(y_val))/len(y_val)\n",
    "            print(\"accuracy:\",acc)\n",
    "\n",
    "            if val_auc > 0.99 and acc > 0.99: \n",
    "                print(\"\\n saving model\")\n",
    "                self.model.save(self.path)\n",
    "                self.best_auc = val_auc\n",
    "                #进行test\n",
    "\n",
    "                y_val_predict_all = []\n",
    "                csv_list=[]\n",
    "                y_val_predict = []\n",
    "\n",
    "                #读取验证集normal的一张图像\n",
    "                for name in os.listdir(\"../data/xuelang_round1_test_a_20180709\"):\n",
    "                    img = cv2.imread(\"../data/xuelang_round1_test_a_20180709/\" + name)\n",
    "                    #转换为rgb\n",
    "                    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "                    img = cv2.resize(img, (800, 600), interpolation=cv2.INTER_AREA)\n",
    "                    batch_x = np.zeros((1,600,800,3),backend.floatx())\n",
    "                    batch_x[0] = img\n",
    "\n",
    "                    y_val_predict = self.model.predict(batch_x/255.,verbose=1,batch_size=8)\n",
    "                    y_val_predict = np.max(y_val_predict,axis=0)[0]\n",
    "                    csv_list.append((name,y_val_predict))\n",
    "                print(\"预测完成\")\n",
    "\n",
    "                import datetime\n",
    "                csv_name = \"../submit/submit_\"+datetime.datetime.now().strftime('%Y%m%d_%H%M%S')+\".csv\"\n",
    "                with open(csv_name,\"a+\",newline='') as csv_file:\n",
    "                    fieldnames = ['filename', 'probability']\n",
    "                    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "                    writer.writeheader()\n",
    "                    for img_name, prob in csv_list:\n",
    "                        #print(np.round(np.clip(prob,0.000001,0.999999),6))\n",
    "                        writer.writerow({'filename': img_name, 'probability': np.round(np.clip(prob,0.000001,0.999999),6)})\n",
    "\n",
    "    from keras.utils import multi_gpu_model\n",
    "    from keras.optimizers import SGD\n",
    "    # Replicates `model` on 8 GPUs.\n",
    "    # This assumes that your machine has 8 available GPUs.\n",
    "    parallel_model = multi_gpu_model(densenet_model, gpus=2)\n",
    "    parallel_model.compile(loss='categorical_crossentropy',optimizer=adam,metrics = ['accuracy'])\n",
    "    history = parallel_model.fit_generator(train_generator,verbose=1,epochs=100,callbacks=[CustomModelCheckpoint(densenet_model,'checkpoint.h5')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
